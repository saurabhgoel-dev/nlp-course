{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'C:\\\\Users\\\\saura\\\\Desktop\\\\MSc Data Science - Birbeck\\\\Natural Language\\\\Class3\\\\inaugural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find all .txt files in the specified directory\n",
    "txt_files = glob.glob(os.path.join(directory_path, '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the contents of each .txt file\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        print(f\"Contents of {txt_file}:\\n{content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "#assign the string of common punctuation symbols to a variable and turn it into a list\n",
    "punctuations = list(string.punctuation)\n",
    "\n",
    "#see what punctuation is included\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        content_tokens = word_tokenize(content)\n",
    "        content_tokens_clean = [word for word in content_tokens if word not in punctuations]\n",
    "        # print(content_tokens_clean)\n",
    "        # print(set(content_tokens_clean))\n",
    "        # print(len(set(content_tokens_clean)))\n",
    "        # print(len(content_tokens_clean))\n",
    "        ttr = len(set(content_tokens_clean))/len(content_tokens_clean)\n",
    "        print(f\"TTR for {txt_file} : {ttr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellow-Citizens of the Senate 0 29 ORG\n",
      "the House of Representatives 37 65 ORG\n",
      "the 14th day 244 256 DATE\n",
      "the present month 260 277 DATE\n",
      "Country 317 324 ORG\n",
      "years 537 542 DATE\n",
      "every day 575 584 DATE\n",
      "first 2055 2060 ORDINAL\n",
      "the United States a Government 2335 2365 GPE\n",
      "the Great Author of every 2574 2599 EVENT\n",
      "the United States 2876 2893 GPE\n",
      "republican 5795 5805 NORP\n",
      "American 5936 5944 NORP\n",
      "fifth 6112 6117 ORDINAL\n",
      "Constitution 6133 6145 LAW\n",
      "the House of Representatives 7111 7139 ORG\n",
      "first 7216 7221 ORDINAL\n",
      "Parent of the Human Race 8117 8141 WORK_OF_ART\n",
      "American 8210 8218 NORP\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    txt_file = txt_files[0]\n",
    "    with open(txt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        content_nlp = nlp(content)\n",
    "        for ent in content_nlp.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
